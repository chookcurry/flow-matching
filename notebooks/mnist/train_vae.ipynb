{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms  # type: ignore\n",
    "from flow_matching.mnist.vae import MNISTVAE, VAETrainer\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749297ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "val_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Subset(train_dataset, torch.randperm(len(train_dataset))[:8192].int()),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    Subset(val_dataset, range(2000)), batch_size=200, shuffle=False\n",
    ")\n",
    "\n",
    "model = MNISTVAE()\n",
    "trainer = VAETrainer(model, train_loader, val_loader, track=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1261b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with size: 1.395 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 30979.961: 100%|██████████| 64/64 [00:14<00:00,  4.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 23536.066, KID: 0.005, Precision: 1.000, Recall: 0.000, F1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 27234.090: 100%|██████████| 64/64 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 20688.539, KID: 0.004, Precision: 1.000, Recall: 0.000, F1: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 25039.652: 100%|██████████| 64/64 [00:14<00:00,  4.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 19675.129, KID: 0.004, Precision: 1.000, Recall: 0.001, F1: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 25719.697: 100%|██████████| 64/64 [00:14<00:00,  4.41it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 19067.332, KID: 0.004, Precision: 1.000, Recall: 0.005, F1: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 24866.637: 100%|██████████| 64/64 [00:14<00:00,  4.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 18690.889, KID: 0.005, Precision: 1.000, Recall: 0.013, F1: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 25035.559: 100%|██████████| 64/64 [00:14<00:00,  4.28it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 18425.084, KID: 0.005, Precision: 1.000, Recall: 0.022, F1: 0.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 24609.418: 100%|██████████| 64/64 [00:15<00:00,  4.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 18135.350, KID: 0.004, Precision: 0.999, Recall: 0.033, F1: 0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 24184.510: 100%|██████████| 64/64 [00:14<00:00,  4.28it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 18014.016, KID: 0.004, Precision: 1.000, Recall: 0.043, F1: 0.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 23936.711: 100%|██████████| 64/64 [00:14<00:00,  4.32it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 17785.121, KID: 0.005, Precision: 1.000, Recall: 0.060, F1: 0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 23277.268: 100%|██████████| 64/64 [00:14<00:00,  4.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 17564.586, KID: 0.004, Precision: 0.998, Recall: 0.082, F1: 0.150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 22344.984: 100%|██████████| 64/64 [00:14<00:00,  4.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 17428.578, KID: 0.003, Precision: 1.000, Recall: 0.112, F1: 0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 22608.355: 100%|██████████| 64/64 [00:14<00:00,  4.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 17309.260, KID: 0.003, Precision: 0.999, Recall: 0.128, F1: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 22489.172: 100%|██████████| 64/64 [00:15<00:00,  4.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 17154.160, KID: 0.002, Precision: 0.998, Recall: 0.131, F1: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 23414.389: 100%|██████████| 64/64 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 17065.387, KID: 0.003, Precision: 0.998, Recall: 0.173, F1: 0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 22765.979: 100%|██████████| 64/64 [00:14<00:00,  4.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 16930.877, KID: 0.002, Precision: 0.998, Recall: 0.216, F1: 0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 22193.877: 100%|██████████| 64/64 [00:14<00:00,  4.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 16808.051, KID: 0.002, Precision: 0.998, Recall: 0.248, F1: 0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 22593.342: 100%|██████████| 64/64 [00:14<00:00,  4.42it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 16670.004, KID: 0.001, Precision: 0.993, Recall: 0.319, F1: 0.480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 21304.867: 100%|██████████| 64/64 [00:14<00:00,  4.30it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 16179.781, KID: 0.001, Precision: 0.975, Recall: 0.635, F1: 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 20690.719: 100%|██████████| 64/64 [00:15<00:00,  4.21it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 15897.172, KID: 0.000, Precision: 0.961, Recall: 0.684, F1: 0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 20080.111: 100%|██████████| 64/64 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 15825.703, KID: 0.000, Precision: 0.961, Recall: 0.707, F1: 0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 20960.117: 100%|██████████| 64/64 [00:14<00:00,  4.32it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 15732.686, KID: 0.000, Precision: 0.959, Recall: 0.714, F1: 0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 20766.703: 100%|██████████| 64/64 [00:14<00:00,  4.41it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 15725.683, KID: -0.000, Precision: 0.961, Recall: 0.683, F1: 0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 20009.992: 100%|██████████| 64/64 [00:14<00:00,  4.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 15715.865, KID: 0.000, Precision: 0.969, Recall: 0.685, F1: 0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 20094.479: 100%|██████████| 64/64 [00:14<00:00,  4.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 15629.631, KID: -0.000, Precision: 0.952, Recall: 0.713, F1: 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 19874.137: 100%|██████████| 64/64 [00:14<00:00,  4.35it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 15639.135, KID: 0.000, Precision: 0.956, Recall: 0.694, F1: 0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 20175.713: 100%|██████████| 64/64 [00:15<00:00,  4.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 15577.950, KID: 0.000, Precision: 0.965, Recall: 0.703, F1: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 19527.939: 100%|██████████| 64/64 [00:14<00:00,  4.32it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 15616.458, KID: 0.001, Precision: 0.940, Recall: 0.761, F1: 0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 20435.639: 100%|██████████| 64/64 [00:14<00:00,  4.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 15555.201, KID: 0.000, Precision: 0.954, Recall: 0.691, F1: 0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 20078.980: 100%|██████████| 64/64 [00:15<00:00,  4.26it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 15546.112, KID: 0.000, Precision: 0.954, Recall: 0.733, F1: 0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 20364.459: 100%|██████████| 64/64 [00:14<00:00,  4.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 15529.924, KID: 0.000, Precision: 0.956, Recall: 0.738, F1: 0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 20516.404: 100%|██████████| 64/64 [00:14<00:00,  4.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 15487.365, KID: 0.000, Precision: 0.957, Recall: 0.718, F1: 0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 19998.861: 100%|██████████| 64/64 [00:14<00:00,  4.28it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 15472.099, KID: 0.000, Precision: 0.960, Recall: 0.708, F1: 0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 19707.418:  62%|██████▎   | 40/64 [00:09<00:05,  4.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/src/flow_matching/mnist/vae.py:130\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(self, num_epochs, device, lr, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m for epoch in range(num_epochs):\n\u001b[32m    128\u001b[39m     self.model.train()\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     # Train loop\n\u001b[32m    131\u001b[39m     pbar = tqdm(self.train_loader)\n\u001b[32m    132\u001b[39m     for idx, batch in enumerate(pbar):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/src/flow_matching/mnist/vae.py:180\u001b[39m, in \u001b[36mget_train_loss\u001b[39m\u001b[34m(self, batch, device)\u001b[39m\n\u001b[32m    177\u001b[39m             \u001b[38;5;28mself\u001b[39m.run.track(val_recall.item(), name=\u001b[33m\"\u001b[39m\u001b[33mval_recall\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m             \u001b[38;5;28mself\u001b[39m.run.track(val_f1.item(), name=\u001b[33m\"\u001b[39m\u001b[33mval_f1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_train_loss\u001b[39m(\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m, batch: Tuple[torch.Tensor, torch.Tensor], device: torch.device\n\u001b[32m    182\u001b[39m ) -> torch.Tensor:\n\u001b[32m    183\u001b[39m     x, _ = batch\n\u001b[32m    184\u001b[39m     recon, mu, logvar = \u001b[38;5;28mself\u001b[39m.model(x.to(device))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/src/flow_matching/mnist/vae.py:79\u001b[39m, in \u001b[36mMNIST_VAE.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mself\u001b[39m, x: torch.Tensor\n\u001b[32m     78\u001b[39m ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     mu, logvar = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     z = \u001b[38;5;28mself\u001b[39m.reparameterize(mu, logvar)\n\u001b[32m     81\u001b[39m     recon = \u001b[38;5;28mself\u001b[39m.decoder(z)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/src/flow_matching/mnist/vae.py:35\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# B x 128 x 4 x 4\u001b[39;00m\n\u001b[32m     36\u001b[39m     mu = \u001b[38;5;28mself\u001b[39m.mu_layer(h)  \u001b[38;5;66;03m# B x 32 x 4 x 4\u001b[39;00m\n\u001b[32m     37\u001b[39m     logvar = \u001b[38;5;28mself\u001b[39m.logvar_layer(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/modules/normalization.py:313\u001b[39m, in \u001b[36mGroupNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/flow-matching/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2965\u001b[39m, in \u001b[36mgroup_norm\u001b[39m\u001b[34m(input, num_groups, weight, bias, eps)\u001b[39m\n\u001b[32m   2958\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2959\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2960\u001b[39m     )\n\u001b[32m   2961\u001b[39m _verify_batch_size(\n\u001b[32m   2962\u001b[39m     [\u001b[38;5;28minput\u001b[39m.size(\u001b[32m0\u001b[39m) * \u001b[38;5;28minput\u001b[39m.size(\u001b[32m1\u001b[39m) // num_groups, num_groups]\n\u001b[32m   2963\u001b[39m     + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m.size()[\u001b[32m2\u001b[39m:])\n\u001b[32m   2964\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2965\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2966\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2967\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer.train(num_epochs=30, device=device, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c63ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"vae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "690e661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "mu, logvar = model.encoder(x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c18d2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = model.reparameterize(mu, logvar)\n",
    "out = model.decoder(z)\n",
    "plt.imshow(out[0].permute(1, 2, 0).detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcb5a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KID: 0.0034\n",
      "Precision: 0.8125\n",
      "Recall: 0.7500\n",
      "F1: 0.7800\n"
     ]
    }
   ],
   "source": [
    "from flow_matching.evaluation.f1 import f1_score, precision_recall_knn\n",
    "from flow_matching.evaluation.kid import kernel_inception_distance_polynomial\n",
    "\n",
    "\n",
    "kid = kernel_inception_distance_polynomial(x, out)\n",
    "precision, recall = precision_recall_knn(x, out)\n",
    "f1 = f1_score(precision, recall)\n",
    "print(f\"KID: {kid:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
